"""
æ•´åˆç¬¬ä¸‰æ–¹å¹³å°ä»·æ ¼åˆ°products.json
è¯»å– thirdparty_prices.jsonï¼Œæ›´æ–° products.json ä¸­çš„Best Buyã€eBayã€Walmartä»·æ ¼
"""

import json
import os
from datetime import datetime


def integrate_thirdparty_prices():
    """æ•´åˆç¬¬ä¸‰æ–¹å¹³å°ä»·æ ¼"""

    print("\n" + "="*70)
    print("ğŸ”§ æ•´åˆç¬¬ä¸‰æ–¹å¹³å°ä»·æ ¼æ•°æ®")
    print("="*70)

    # è¯»å–ç¬¬ä¸‰æ–¹å¹³å°ä»·æ ¼
    thirdparty_file = '../data/thirdparty_prices.json'
    products_file = '../data/products.json'

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(thirdparty_file):
        print(f"âš ï¸  ç¬¬ä¸‰æ–¹ä»·æ ¼æ–‡ä»¶ä¸å­˜åœ¨: {thirdparty_file}")
        print("   Playwrightçˆ¬è™«å¯èƒ½è¿˜æœªè¿è¡Œï¼Œè·³è¿‡æ•´åˆ")
        return False

    # è¯»å–ç¬¬ä¸‰æ–¹ä»·æ ¼
    print(f"\nğŸ“– è¯»å–ç¬¬ä¸‰æ–¹ä»·æ ¼: {thirdparty_file}")
    with open(thirdparty_file, 'r', encoding='utf-8') as f:
        thirdparty_data = json.load(f)

    scraped_products = thirdparty_data.get('products', [])
    print(f"âœ… æ‰¾åˆ° {len(scraped_products)} ä¸ªäº§å“çš„ç¬¬ä¸‰æ–¹ä»·æ ¼")
    print(f"   æˆåŠŸç‡: {thirdparty_data.get('success_rate', 'N/A')}")

    # è¯»å–äº§å“æ•°æ®
    if not os.path.exists(products_file):
        print(f"âŒ äº§å“æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {products_file}")
        return False

    print(f"\nğŸ“– è¯»å–äº§å“æ•°æ®: {products_file}")
    with open(products_file, 'r', encoding='utf-8') as f:
        dashboard_data = json.load(f)

    products = dashboard_data.get('products', [])
    print(f"âœ… æ‰¾åˆ° {len(products)} ä¸ªäº§å“")

    # åˆ›å»ºä»·æ ¼æ˜ å°„ï¼ˆå“ç‰Œ+äº§å“å â†’ ä»·æ ¼å’ŒURLï¼‰
    price_map = {}
    for item in scraped_products:
        key = f"{item['brand']}_{item['name']}"
        price_map[key] = {
            'prices': item['prices'],
            'urls': item.get('urls', {})
        }

    print(f"\nğŸ”„ å¼€å§‹æ•´åˆç¬¬ä¸‰æ–¹å¹³å°ä»·æ ¼å’ŒURL...")
    updated_count = 0

    # æ›´æ–°äº§å“æ•°æ®
    for product in products:
        brand = product.get('brand', '')
        name = product.get('name', '')
        key = f"{brand}_{name}"

        if key in price_map:
            data = price_map[key]
            prices_data = data['prices']
            urls_data = data['urls']

            # æ›´æ–°Best Buyä»·æ ¼å’ŒURL
            if prices_data.get('bestbuy') and 'channels' in product:
                if 'bestbuy' not in product['channels']:
                    product['channels']['bestbuy'] = {}

                old_price = product['channels'].get('bestbuy', {}).get('price')
                new_price = prices_data['bestbuy']

                product['channels']['bestbuy']['price'] = new_price
                product['channels']['bestbuy']['confidence'] = 'VERIFIED_PLAYWRIGHT'
                product['channels']['bestbuy']['price_source'] = 'Playwright Scraper - Direct URL'

                # æ›´æ–°URLï¼ˆé‡è¦ï¼ç”¨äºç‚¹å‡»è·³è½¬ï¼‰
                if urls_data.get('bestbuy'):
                    product['channels']['bestbuy']['url'] = urls_data['bestbuy']

                print(f"  âœ… {brand} {name} - Best Buy: ${old_price} â†’ ${new_price}")
                updated_count += 1

            # æ›´æ–°eBayä»·æ ¼å’ŒURL
            if prices_data.get('ebay') and 'channels' in product and 'ebay' in product['channels']:
                old_price = product['channels']['ebay'].get('price')
                new_price = prices_data['ebay']

                product['channels']['ebay']['price'] = new_price
                product['channels']['ebay']['confidence'] = 'VERIFIED_PLAYWRIGHT'
                product['channels']['ebay']['price_source'] = 'Playwright Scraper - Direct URL'

                # æ›´æ–°URLï¼ˆé‡è¦ï¼ç”¨äºç‚¹å‡»è·³è½¬ï¼‰
                if urls_data.get('ebay'):
                    product['channels']['ebay']['url'] = urls_data['ebay']

                print(f"  âœ… {brand} {name} - eBay: ${old_price} â†’ ${new_price}")

            # æ›´æ–°Walmartä»·æ ¼ï¼ˆå¦‚æœæœ‰ï¼‰
            if prices_data.get('walmart') and 'channels' in product and 'walmart' in product['channels']:
                old_price = product['channels']['walmart'].get('price')
                new_price = prices_data['walmart']

                product['channels']['walmart']['price'] = new_price
                product['channels']['walmart']['confidence'] = 'VERIFIED_PLAYWRIGHT'
                product['channels']['walmart']['price_source'] = 'Playwright Scraper'

                print(f"  âœ… {brand} {name} - Walmart: ${old_price} â†’ ${new_price}")

    print(f"\nâœ… æ›´æ–°äº† {updated_count} ä¸ªäº§å“çš„ç¬¬ä¸‰æ–¹å¹³å°ä»·æ ¼")

    # æ›´æ–°last_updateæ—¶é—´
    dashboard_data['last_update'] = datetime.now().isoformat()

    # ä¿å­˜æ›´æ–°åçš„æ•°æ®
    print(f"\nğŸ’¾ ä¿å­˜æ›´æ–°åçš„æ•°æ®åˆ°: {products_file}")
    with open(products_file, 'w', encoding='utf-8') as f:
        json.dump(dashboard_data, f, indent=2, ensure_ascii=False)

    print("\n" + "="*70)
    print("âœ… ç¬¬ä¸‰æ–¹å¹³å°ä»·æ ¼æ•´åˆå®Œæˆï¼")
    print("="*70)
    print()

    return True


if __name__ == "__main__":
    success = integrate_thirdparty_prices()
    exit(0 if success else 1)
