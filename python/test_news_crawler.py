"""
å¿«é€Ÿæµ‹è¯•æ–°é—»çˆ¬è™«
æ— éœ€APIå¯†é’¥ï¼Œä½¿ç”¨Google News RSS
"""

from auto_news_fetcher import MultiSourceNewsFetcher
import json

def test_crawler():
    print("\n" + "="*70)
    print("ğŸ§ª æµ‹è¯•æ–°é—»çˆ¬è™«ï¼ˆä½¿ç”¨å…è´¹çš„Google News RSSï¼‰")
    print("="*70)

    # åˆ›å»ºçˆ¬è™«å®ä¾‹
    fetcher = MultiSourceNewsFetcher()

    # æµ‹è¯•å•ä¸ªå“ç‰Œ
    print("\nğŸ“ æµ‹è¯•1: è·å–Eufyå“ç‰Œæ–°é—»...")
    eufy_news = fetcher.fetch_brand_news('Eufy')

    print(f"\nâœ… æˆåŠŸè·å– {len(eufy_news)} æ¡Eufyæ–°é—»:")
    for idx, news in enumerate(eufy_news, 1):
        print(f"\n  [{idx}] {news['title']}")
        print(f"      æ¥æº: {news['source']}")
        print(f"      æ—¥æœŸ: {news['date']}")
        print(f"      URL: {news['url'][:80]}...")

    # æµ‹è¯•æ‰€æœ‰å“ç‰Œ
    print("\n" + "="*70)
    print("ğŸ“ æµ‹è¯•2: è·å–æ‰€æœ‰å“ç‰Œæ–°é—»...")
    print("="*70)

    all_news = fetcher.fetch_all_brands()

    # ç»Ÿè®¡
    brand_counts = {}
    for news in all_news:
        brand = news['brand']
        brand_counts[brand] = brand_counts.get(brand, 0) + 1

    print("\nğŸ“Š ç»Ÿè®¡ç»“æœ:")
    for brand, count in sorted(brand_counts.items()):
        status = "âœ…" if count >= 5 else "âš ï¸ "
        print(f"  {status} {brand}: {count} æ¡æ–°é—»")

    print(f"\nâœ… æ€»è®¡: {len(all_news)} æ¡æ–°é—»")

    # ä¿å­˜ç¤ºä¾‹
    print("\nğŸ’¾ ä¿å­˜ç¤ºä¾‹æ–°é—»åˆ° test_news_output.json")
    with open('test_news_output.json', 'w', encoding='utf-8') as f:
json.dump({
            'total': len(all_news),
            'by_brand': brand_counts,
            'sample_news': all_news[:5]
        }, f, indent=2, ensure_ascii=False)

    print("\n" + "="*70)
    if len(all_news) >= 40:
        print("âœ… æµ‹è¯•æˆåŠŸï¼æ–°é—»çˆ¬è™«å·¥ä½œæ­£å¸¸ï¼")
    else:
        print(f"âš ï¸  è­¦å‘Š: åªè·å–åˆ° {len(all_news)} æ¡æ–°é—»ï¼ˆé¢„æœŸ40æ¡ï¼‰")
        print("   è¿™å¯èƒ½æ˜¯ä¸´æ—¶çš„ç½‘ç»œé—®é¢˜ï¼Œå¯ä»¥é‡è¯•")
    print("="*70)
    print()

if __name__ == "__main__":
    test_crawler()
